# ğŸ§  AI-Image-Descriptor

A simple yet powerful web app that uses the BLIP model to generate intelligent captions for images â€” either uploaded by the user or scraped from any URL. Built with Gradio, Transformers, and Torch.

ğŸ§ª Live Demo

ğŸ‘‰ Try it here: https://huggingface.co/spaces/layer-rep/Image_Captions

![image](https://github.com/user-attachments/assets/f50c8707-65fd-4be0-9621-873415061356)


> âœ… Works locally with Python 3.12  
> âœ… Compatible with CPU and GPU  
> âœ… Lightweight and fast â€” uses `Salesforce/blip-image-captioning-base`  
> âœ… Built-in UI using Gradio  

---

## ğŸš€ Features

- **Upload images** or paste a **webpage URL**
- Generates **descriptive captions** using BLIP
- Captions the **first 3 usable images** on any webpage
- Fast setup with a **single Python file**
- One-click **copy-to-clipboard**
- Clean, responsive **Gradio UI**
- Fully documented, beginner-friendly code

---

## ğŸ–¼ï¸ Demo Preview

> ğŸ“¸ *(Optional: You can add a screenshot here using `![Alt Text](url)`)*  
*Drag and drop images, or caption directly from a URL.*

---

## ğŸ§  Model Used

- [`Salesforce/blip-image-captioning-base`](https://huggingface.co/Salesforce/blip-image-captioning-base)  
  A lightweight BLIP model optimized for fast, local captioning without tokenizer issues.

---

## ğŸ“¦ Requirements

All dependencies are listed in `requirements.txt`. Install with:

```bash
pip install -r requirements.txt


ğŸ› ï¸ Setup Instructions
âœ… Python 3.12 compatible

1. Clone the repo
git clone https://github.com/srimaansri/AI-Image-Descriptor.git
cd AI-Image-Descriptor

2. (Optional) Create a virtual environment

python -m venv venv
venv\Scripts\activate  # On Windows

3. Install dependencies
pip install -r requirements.txt

4. Run the app
python gradio_blip2_app.py
